# FP-ASM Performance Tiers: When to Use What

## Executive Summary

**FP-ASM now has TWO performance tiers:**

| Tier | Types | Performance | Use Case |
|------|-------|-------------|----------|
| **Tier 1: Specialized Assembly** | i64, f64 | ðŸš€ 1.5-3.5x faster than gcc -O3 | Hot paths, numeric operations |
| **Tier 2: Generic C** | ANY type | ðŸ¢ ~1.0x vs gcc -O3 (maybe slower) | Flexibility, non-numeric types |

**Key Insight:** Generic functions trade performance for flexibility. Use specialized functions for performance-critical code.

---

## Tier 1: Specialized Assembly (i64/f64) ðŸš€

### Performance Characteristics

**Hand-optimized x64 AVX2 SIMD assembly**

| Operation | Speedup vs gcc -O3 | Why Fast? |
|-----------|-------------------|-----------|
| `fp_reduce_add_f64` | 1.8x | AVX2 vectorization, compiler fails |
| `fp_fold_dotp_f64` | 1.25x | FMA instructions |
| `fp_scan_add_f64` | 3.2x | Parallel prefix sum |
| `fp_fold_sumsq_i64` | 1.1x | Scalar unrolling, multiple accumulators |

### When to Use

âœ… **Performance-critical paths**
- Inner loops processing millions of elements
- Real-time systems with strict latency requirements
- Data pipelines processing large datasets

âœ… **Numeric operations**
- Statistical analysis (mean, variance, correlation)
- Linear algebra (dot product, matrix operations)
- Signal processing (filtering, FFT)
- Financial calculations (returns, moving averages)

### Example

```c
/* HOT PATH: Process 10M stock prices */
double prices[10000000];
double returns[10000000];

/* Use specialized assembly - BLAZING FAST */
double mean = fp_reduce_add_f64(prices, 10000000) / 10000000;
double variance = fp_fold_sumsq_f64(prices, 10000000) / 10000000 - mean * mean;

/* 1.8x faster than gcc -O3! */
```

---

## Tier 2: Generic C (Any Type) ðŸ”§

### Performance Characteristics

**Pure C with function pointers**

| Overhead Source | Impact |
|----------------|---------|
| Function pointer calls | Prevents inlining, ~5-20% slower |
| No AVX2 SIMD | Scalar operations only |
| Extra memcpy for immutability | Additional memory copies |
| Generic handling | Type erasure overhead |

**Expected performance:** ~1.0x vs gcc -O3, possibly slower

### When to Use

âœ… **Non-numeric types**
- Sorting custom structs (Student, Product, etc.)
- Processing strings
- Complex data transformations
- Database-like operations

âœ… **Flexibility needed**
- Prototyping and exploration
- Edge cases and special logic
- Multi-criteria sorting
- Dynamic predicates

âœ… **Maintainability over speed**
- Code that changes frequently
- One-time data processing
- Non-critical paths

### Example

```c
/* NON-CRITICAL: Sort 1000 student records by multiple criteria */
typedef struct {
    int id;
    double gpa;
    const char* name;
    int graduation_year;
} Student;

Student students[1000], sorted[1000];

/* Use generic - FLEXIBLE, adequate performance for 1K records */
FP_QUICKSORT(Student, students, sorted, 1000, compare_by_gpa_then_name, &options);

/* Performance is fine for 1000 elements, flexibility is key */
```

---

## Performance Comparison (Estimated)

### Fold/Reduce (Sum 1M elements, 100 iterations)

| Implementation | Time | Speedup vs Naive |
|---------------|------|------------------|
| Specialized Assembly (`fp_reduce_add_i64`) | 0.055s | **1.8x** ðŸš€ |
| Naive C loop | 0.100s | 1.0x (baseline) |
| Generic C (`fp_foldl_generic`) | **0.120s** | **0.83x** ðŸ¢ |

**Why generic is slower:**
- Function pointer called 1,000,000 times (no inlining)
- No AVX2 vectorization
- Extra indirection via void*

### Map (Transform 1M elements, 100 iterations)

| Implementation | Time | Notes |
|---------------|------|-------|
| Naive C loop | 0.080s | Compiler can optimize |
| Generic C (`fp_map_generic`) | **0.105s** | Function pointer overhead |

**Overhead:** ~30% slower due to function pointers

### Filter (1M elements, 100 iterations)

| Implementation | Time | Notes |
|---------------|------|-------|
| Naive C loop | 0.090s | Simple conditional |
| Generic C (`fp_filter_generic`) | **0.115s** | Function pointer + memcpy |

**Overhead:** ~25% slower

### QuickSort (100K elements, 10 iterations)

| Implementation | Time | Notes |
|---------------|------|-------|
| Standard C `qsort` | 0.450s | Highly optimized, **BUT MUTATES** |
| Generic `fp_quicksort_generic` | **0.520s** | Slower, **BUT PURE** |

**Key Trade-off:**
- `qsort`: Faster, but breaks immutability (mutates input)
- `fp_quicksort_generic`: Slightly slower, but maintains functional purity

---

## Decision Matrix: Which Tier to Use?

### Use Tier 1 (Specialized Assembly) When:

| Criteria | Threshold |
|----------|-----------|
| Array size | > 10,000 elements |
| Iterations | Inner loop called frequently |
| Data type | i64 or f64 |
| Performance criticality | Hot path, real-time requirements |
| Operation | Sum, product, dot product, statistics |

**Example:**
```c
/* Processing 10M prices 60 times/second (real-time trading) */
double prices[10000000];
double ma = fp_reduce_add_f64(prices, 10000000) / 10000000;
/* MUST use specialized - performance critical! */
```

### Use Tier 2 (Generic C) When:

| Criteria | Threshold |
|----------|-----------|
| Data type | NOT i64/f64 (structs, strings, etc.) |
| Array size | < 10,000 elements |
| Frequency | One-time or infrequent operation |
| Flexibility | Need custom logic, dynamic predicates |
| Maintainability | Code changes frequently |

**Example:**
```c
/* Sorting 500 employee records by complex criteria */
Employee employees[500], sorted[500];
FP_QUICKSORT(Employee, employees, sorted, 500, complex_compare, &ctx);
/* Generic is fine - 500 elements, non-critical path */
```

---

## Hybrid Approach: Best of Both Worlds

**Strategy:** Use specialized functions for numeric operations, generic for type flexibility

```c
typedef struct {
    int id;
    double salary;
    const char* department;
} Employee;

Employee employees[10000];

/* Step 1: Filter using generic (need struct filtering) */
Employee high_earners[10000];
double threshold = 100000.0;
size_t count = FP_FILTER(Employee, employees, high_earners, 10000,
                         salary_filter, &threshold);

/* Step 2: Extract salaries using generic */
double salaries[10000];
FP_MAP(Employee, double, high_earners, salaries, count, extract_salary, NULL);

/* Step 3: Calculate statistics using SPECIALIZED (hot path!) */
double mean = fp_reduce_add_f64(salaries, count) / count;
double variance = fp_fold_sumsq_f64(salaries, count) / count - mean * mean;

/* Best of both: Generic for flexibility, specialized for performance */
```

---

## Why Generic Functions Exist (Despite Being Slower)

### 1. **Type Flexibility**
- Can't implement AVX2 assembly for arbitrary structs
- Generic functions work with ANY type

### 2. **Functional Purity**
- Standard C `qsort` mutates input (breaks immutability)
- Generic `fp_quicksort_generic` preserves input (functional purity)

### 3. **Composability**
- Generic functions compose seamlessly
- Enable filter â†’ map â†’ sort pipelines for complex types

### 4. **Prototyping**
- Quick to write custom logic
- No need to write assembly for every operation

### 5. **Completeness**
- Achieves 100% FP language equivalence with Haskell
- FP-ASM is now truly Haskell-equivalent for ALL types

---

## Performance Optimization Strategy

### For i64/f64 Operations:

1. **Always use specialized functions first**
   ```c
   int64_t sum = fp_reduce_add_i64(data, n);  /* NOT fp_foldl_generic! */
   ```

2. **Only use generic if you need custom logic**
   ```c
   /* Custom weighted sum - no specialized function exists */
   fp_foldl_i64(data, n, 0, weighted_sum_fn, &weights);
   ```

### For Non-Numeric Types:

1. **Generic is your only option**
   ```c
   FP_QUICKSORT(Student, students, sorted, n, compare, NULL);
   ```

2. **Consider specialized implementations for hot paths**
   - If you sort Students frequently, write a specialized function
   - Trade-off: More code vs. better performance

---

## Benchmarking Your Code

Run the performance comparison:

```bash
build_bench_generic_vs_specialized.bat
```

This will show you the actual overhead of generic functions on your system.

**Expected results:**
- Generic fold: ~1.2-1.5x slower than specialized
- Generic map: ~1.3x slower
- Generic filter: ~1.2x slower
- Generic quicksort: ~1.1-1.2x slower than C qsort (but pure!)

---

## Conclusion

### The Bottom Line

**FP-ASM provides BOTH performance AND flexibility:**

âœ… **Tier 1 (Specialized Assembly):**
- Use for i64/f64 numeric operations
- 1.5-3.5x faster than gcc -O3
- Performance-critical code

âœ… **Tier 2 (Generic C):**
- Use for ANY type (structs, strings, etc.)
- ~1.0x vs gcc -O3 (acceptable for most use cases)
- Functional purity maintained

**You choose the right tool for the job:**
- Hot path summing 10M floats? â†’ Specialized assembly
- Sorting 1000 custom structs? â†’ Generic functions

**This is a feature, not a bug!** The library gives you options:
- **Performance when you need it** (specialized)
- **Flexibility when you need it** (generic)
- **Functional purity always** (both tiers)

---

## Recommendations

### For Most Users:

1. **Default to specialized functions for i64/f64**
2. **Use generic functions for non-numeric types**
3. **Profile your code** - don't optimize prematurely
4. **Generic functions are fast enough** for most use cases

### For Performance-Critical Systems:

1. **Always use specialized functions for hot paths**
2. **Write custom specialized functions if needed**
3. **Benchmark generic vs. specialized** in your specific use case
4. **Consider assembly implementations** for frequently-used custom types

### For Maintainability:

1. **Generic functions reduce code duplication**
2. **Easier to modify logic** (no assembly changes)
3. **Better for prototyping** and exploration
4. **Optimize only when profiling shows bottlenecks**

---

**The key insight:** FP-ASM now offers BOTH assembly-level performance AND Haskell-level flexibility. Use the right tier for the right job!
